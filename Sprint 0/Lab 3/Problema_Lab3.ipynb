{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías necesarias\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acceso a los datos de ventas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga el dataset de ventas. ¿Cuántas unidades de cualquier helado se han vendido en total a lo largo del histórico?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>id_producto</th>\n",
       "      <th>ventas_unidades</th>\n",
       "      <th>precio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>4758</td>\n",
       "      <td>7953</td>\n",
       "      <td>4.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>17</td>\n",
       "      <td>7052</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>9134</td>\n",
       "      <td>6403</td>\n",
       "      <td>2.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>8689</td>\n",
       "      <td>4266</td>\n",
       "      <td>2.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>402</td>\n",
       "      <td>2932</td>\n",
       "      <td>2.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fecha  id_producto  ventas_unidades  precio\n",
       "0 2019-01-07         4758             7953    4.82\n",
       "1 2019-01-07           17             7052    1.50\n",
       "2 2019-01-07         9134             6403    2.36\n",
       "3 2019-01-07         8689             4266    2.47\n",
       "4 2019-01-07          402             2932    2.89"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('./ventas_helados.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Se han vendido un total de: 3848068 helados\n"
     ]
    }
   ],
   "source": [
    "total_units_sold = df['ventas_unidades'].sum()\n",
    "print(f'\\nSe han vendido un total de: {total_units_sold} helados')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuál es el identificador del helado con más ventas en euros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_producto\n",
      "17      998119\n",
      "101      27127\n",
      "240     202538\n",
      "402     266723\n",
      "999      20468\n",
      "2033    209155\n",
      "3636     32070\n",
      "4468     14473\n",
      "4577    130704\n",
      "4758    449007\n",
      "5019     17401\n",
      "5684     45269\n",
      "6525     62213\n",
      "7118      4051\n",
      "8689    689257\n",
      "9134    679493\n",
      "Name: ventas_unidades, dtype: int64\n",
      "\n",
      "El ID del helado con más ventas es: 17\n"
     ]
    }
   ],
   "source": [
    "# Agrupamos los datos de ventas por helado y el identificador del helado\n",
    "ventas_por_helado = df.groupby('id_producto')['ventas_unidades'].sum()\n",
    "print(ventas_por_helado)\n",
    "\n",
    "# Encontrar el helado con las ventas más altas\n",
    "id_helado_max_ventas = ventas_por_helado.idxmax()\n",
    "\n",
    "print(\"\\nEl ID del helado con más ventas es:\", id_helado_max_ventas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acceso a los datos de publicidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lee los datos de publicidad, y transformalos en una serie semanal con la suma de todos los medios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>inversion_tv</th>\n",
       "      <th>inversion_radio</th>\n",
       "      <th>inversion_youtube</th>\n",
       "      <th>inversion_facebook</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>6100</td>\n",
       "      <td>0</td>\n",
       "      <td>6100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-21</td>\n",
       "      <td>1120</td>\n",
       "      <td>0</td>\n",
       "      <td>1120</td>\n",
       "      <td>5610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>880</td>\n",
       "      <td>880</td>\n",
       "      <td>880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fecha  inversion_tv  inversion_radio  inversion_youtube  \\\n",
       "0 2019-01-07          6100                0               6100   \n",
       "1 2019-01-14             0                0                  0   \n",
       "2 2019-01-21          1120                0               1120   \n",
       "3 2019-01-28             0                0                  0   \n",
       "4 2019-02-04           880              880                880   \n",
       "\n",
       "   inversion_facebook  \n",
       "0                   0  \n",
       "1                6530  \n",
       "2                5610  \n",
       "3                1510  \n",
       "4                   0  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('./inversiones_helados.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> \u001b[1;32mc:\\users\\hugoc\\appdata\\local\\temp\\ipykernel_14304\\1642933984.py\u001b[0m(7)\u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\n",
      "fecha\n",
      "2019-01-07   NaN\n",
      "2019-01-14   NaN\n",
      "2019-01-21   NaN\n",
      "2019-01-28   NaN\n",
      "2019-02-04   NaN\n",
      "              ..\n",
      "2020-11-30   NaN\n",
      "2020-12-07   NaN\n",
      "2020-12-14   NaN\n",
      "2020-12-21   NaN\n",
      "2020-12-28   NaN\n",
      "Name: total_inversion, Length: 104, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Agrupar por semana y sumar las inversiones de todos los medios\n",
    "# serie_semanal = df.groupby(pd.Grouper(key='fecha')).sum()\n",
    "\n",
    "# Sumar las inversiones de todos los medios para cada semana\n",
    "df['total_inversiones'] = df[['inversion_tv', 'inversion_radio', 'inversion_youtube', 'inversion_facebook']].sum(axis=1)\n",
    "\n",
    "import pdb; pdb.set_trace()\n",
    "\n",
    "serie_total_inversion = pd.Series(df['total_inversiones'], name='total_inversion', index=df['fecha'])\n",
    "\n",
    "print(serie_total_inversion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuál es el mes con más inversión total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'The grouper name fecha is not found'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[153], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Agrupar por mes y sumar las inversiones de todos los medios\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m serie_mensual \u001b[38;5;241m=\u001b[39m \u001b[43mserie_total_inversion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGrouper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfecha\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mME\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Sumar las inversiones de todos los medios para cada mes\u001b[39;00m\n\u001b[0;32m      5\u001b[0m serie_mensual[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_inversion\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m serie_mensual\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hugoc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:2237\u001b[0m, in \u001b[0;36mSeries.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   2234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas_index=False only valid with DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2235\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[1;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2240\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2243\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2247\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hugoc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1334\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1337\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[1;32mc:\\Users\\hugoc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:929\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;66;03m# a passed-in Grouper, directly convert\u001b[39;00m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Grouper):\n\u001b[1;32m--> 929\u001b[0m     grouper, obj \u001b[38;5;241m=\u001b[39m \u001b[43mkey\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_grouper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    931\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m grouper, \u001b[38;5;28mfrozenset\u001b[39m(), obj\n",
      "File \u001b[1;32mc:\\Users\\hugoc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\resample.py:2276\u001b[0m, in \u001b[0;36mTimeGrouper._get_grouper\u001b[1;34m(self, obj, validate)\u001b[0m\n\u001b[0;32m   2272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_grouper\u001b[39m(\n\u001b[0;32m   2273\u001b[0m     \u001b[38;5;28mself\u001b[39m, obj: NDFrameT, validate: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   2274\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[BinGrouper, NDFrameT]:\n\u001b[0;32m   2275\u001b[0m     \u001b[38;5;66;03m# create the resampler and return our binner\u001b[39;00m\n\u001b[1;32m-> 2276\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_resampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r\u001b[38;5;241m.\u001b[39m_grouper, cast(NDFrameT, r\u001b[38;5;241m.\u001b[39mobj)\n",
      "File \u001b[1;32mc:\\Users\\hugoc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\resample.py:2223\u001b[0m, in \u001b[0;36mTimeGrouper._get_resampler\u001b[1;34m(self, obj, kind)\u001b[0m\n\u001b[0;32m   2204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_resampler\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: NDFrame, kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Resampler:\n\u001b[0;32m   2205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2206\u001b[0m \u001b[38;5;124;03m    Return my resampler or raise if we have an invalid axis.\u001b[39;00m\n\u001b[0;32m   2207\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2221\u001b[0m \n\u001b[0;32m   2222\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2223\u001b[0m     _, ax, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_grouper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpr_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   2224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ax, DatetimeIndex):\n\u001b[0;32m   2225\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m DatetimeIndexResampler(\n\u001b[0;32m   2226\u001b[0m             obj,\n\u001b[0;32m   2227\u001b[0m             timegrouper\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2231\u001b[0m             gpr_index\u001b[38;5;241m=\u001b[39max,\n\u001b[0;32m   2232\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\hugoc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\resample.py:2523\u001b[0m, in \u001b[0;36mTimeGrouper._set_grouper\u001b[1;34m(self, obj, sort, gpr_index)\u001b[0m\n\u001b[0;32m   2520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_grouper\u001b[39m(\n\u001b[0;32m   2521\u001b[0m     \u001b[38;5;28mself\u001b[39m, obj: NDFrameT, sort: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, gpr_index: Index \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2522\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[NDFrameT, Index, npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[1;32m-> 2523\u001b[0m     obj, ax, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_grouper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpr_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgpr_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2524\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ax\u001b[38;5;241m.\u001b[39mdtype, ArrowDtype) \u001b[38;5;129;01mand\u001b[39;00m ax\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMm\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2525\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arrow_dtype \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mdtype\n",
      "File \u001b[1;32mc:\\Users\\hugoc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:380\u001b[0m, in \u001b[0;36mGrouper._set_grouper\u001b[1;34m(self, obj, sort, gpr_index)\u001b[0m\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    379\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_info_axis:\n\u001b[1;32m--> 380\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe grouper name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    381\u001b[0m         ax \u001b[38;5;241m=\u001b[39m Index(obj[key], name\u001b[38;5;241m=\u001b[39mkey)\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'The grouper name fecha is not found'"
     ]
    }
   ],
   "source": [
    "# Agrupar por mes y sumar las inversiones de todos los medios\n",
    "serie_mensual = df.groupby(pd.Grouper(key='fecha', freq='ME')).sum()\n",
    "\n",
    "# Sumar las inversiones de todos los medios para cada mes\n",
    "serie_mensual['total_inversion'] = serie_mensual.sum(axis=1)\n",
    "\n",
    "# Crear la serie mensual con la suma de inversiones totales\n",
    "serie_total_inversion_mensual = pd.Series(serie_mensual['total_inversion'], name='total_inversion')\n",
    "\n",
    "print(serie_total_inversion_mensual)\n",
    "\n",
    "# Encontrar el mes con la mayor inversión total\n",
    "mes_max_inversion = serie_mensual['total_inversion'].idxmax().strftime('%B de %Y')\n",
    "\n",
    "print(\"\\nEl mes con la mayor inversión total es:\", mes_max_inversion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinando datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combina el dataframe de ventas con las descripciones de los productos, y quédate sólo con los productos de helados de tarrina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>id_producto</th>\n",
       "      <th>ventas_unidades</th>\n",
       "      <th>precio</th>\n",
       "      <th>nombre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>2033</td>\n",
       "      <td>1862</td>\n",
       "      <td>2.44</td>\n",
       "      <td>CARTE D' OR Helado de yogur Tarrina 500 gr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>240</td>\n",
       "      <td>1015</td>\n",
       "      <td>2.30</td>\n",
       "      <td>Helado Haagen Dazs Cookies Tarrina 400 g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>5684</td>\n",
       "      <td>317</td>\n",
       "      <td>3.70</td>\n",
       "      <td>DIA Helado Fresa Tarrina 1kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>101</td>\n",
       "      <td>208</td>\n",
       "      <td>3.93</td>\n",
       "      <td>MAGNUM Helado White Chocolate &amp; Cookies Tarrin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>3636</td>\n",
       "      <td>160</td>\n",
       "      <td>2.60</td>\n",
       "      <td>CARTE D' OR Helado Stracciatella Tarrina 500 gr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>5019</td>\n",
       "      <td>132</td>\n",
       "      <td>2.45</td>\n",
       "      <td>DIA Helado Dulce de Leche Tarrina 500 g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>7118</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Haagen Dazs Helado Fresa Tarrina 400 g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2019-01-14</td>\n",
       "      <td>2033</td>\n",
       "      <td>1389</td>\n",
       "      <td>2.40</td>\n",
       "      <td>CARTE D' OR Helado de yogur Tarrina 500 gr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2019-01-14</td>\n",
       "      <td>240</td>\n",
       "      <td>873</td>\n",
       "      <td>2.29</td>\n",
       "      <td>Helado Haagen Dazs Cookies Tarrina 400 g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2019-01-14</td>\n",
       "      <td>5684</td>\n",
       "      <td>313</td>\n",
       "      <td>3.56</td>\n",
       "      <td>DIA Helado Fresa Tarrina 1kg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fecha  id_producto  ventas_unidades  precio  \\\n",
       "5  2019-01-07         2033             1862    2.44   \n",
       "8  2019-01-07          240             1015    2.30   \n",
       "10 2019-01-07         5684              317    3.70   \n",
       "11 2019-01-07          101              208    3.93   \n",
       "13 2019-01-07         3636              160    2.60   \n",
       "14 2019-01-07         5019              132    2.45   \n",
       "15 2019-01-07         7118                0     NaN   \n",
       "21 2019-01-14         2033             1389    2.40   \n",
       "24 2019-01-14          240              873    2.29   \n",
       "26 2019-01-14         5684              313    3.56   \n",
       "\n",
       "                                               nombre  \n",
       "5          CARTE D' OR Helado de yogur Tarrina 500 gr  \n",
       "8            Helado Haagen Dazs Cookies Tarrina 400 g  \n",
       "10                       DIA Helado Fresa Tarrina 1kg  \n",
       "11  MAGNUM Helado White Chocolate & Cookies Tarrin...  \n",
       "13    CARTE D' OR Helado Stracciatella Tarrina 500 gr  \n",
       "14            DIA Helado Dulce de Leche Tarrina 500 g  \n",
       "15             Haagen Dazs Helado Fresa Tarrina 400 g  \n",
       "21         CARTE D' OR Helado de yogur Tarrina 500 gr  \n",
       "24           Helado Haagen Dazs Cookies Tarrina 400 g  \n",
       "26                       DIA Helado Fresa Tarrina 1kg  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ventas = pd.read_excel('./ventas_helados.xlsx')\n",
    "df_productos = pd.read_csv('./nombres_productos.csv')\n",
    "\n",
    "# Fusionar los DataFrames en función del id_producto\n",
    "df_combinado = pd.merge(df_ventas, df_productos, on='id_producto', how='inner')\n",
    "\n",
    "# Filtrar los productos de helados de tarrina\n",
    "helados_tarrina = df_combinado[df_combinado['nombre'].str.contains('Tarrina')]\n",
    "\n",
    "helados_tarrina.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrega el dataset anterior en una serie semanal que agregue todos los productos mediante la suma de unidades y la media de los precios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            suma_unidades  media_precios\n",
      "fecha                                   \n",
      "2019-01-13           3694       2.903333\n",
      "2019-01-20           3052       2.846667\n",
      "2019-01-27           2952       2.820000\n",
      "2019-02-03           3165       2.890000\n",
      "2019-02-10           3211       2.925000\n",
      "...                   ...            ...\n",
      "2020-12-06           4144       2.827143\n",
      "2020-12-13           5336       2.765714\n",
      "2020-12-20           5566       2.797143\n",
      "2020-12-27           5853       2.777143\n",
      "2021-01-03           6090       2.754286\n",
      "\n",
      "[104 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Agrupar por semana y calcular suma de unidades y media de precios\n",
    "serie_semanal_ventas = helados_tarrina.groupby(pd.Grouper(key='fecha', freq='W'))['ventas_unidades'].sum()\n",
    "serie_semanal_precios = helados_tarrina.groupby(pd.Grouper(key='fecha', freq='W'))['precio'].mean()\n",
    "\n",
    "# Crear dos nuevas series con la suma de unidades y la media de precios\n",
    "serie_suma_unidades = pd.Series(serie_semanal_ventas.values, index=serie_semanal_ventas.index, name='suma_unidades')\n",
    "serie_media_precios = pd.Series(serie_semanal_precios.values, index=serie_semanal_precios.index, name='media_precios')\n",
    "\n",
    "# Crear una nueva serie combinando las dos series anteriores\n",
    "serie_semanal = pd.concat([serie_suma_unidades, serie_media_precios], axis=1)\n",
    "\n",
    "print(serie_semanal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combina todos los dataframes en uno solo (llamado dataset_conjunto), partiendo del dataset con los datos de helados de tarrina agregados por semana. Utiliza left joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea una variable binaria <i>navidad</i> que valga 1 en las semanas de nochebuena y nochevieja\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jugando con expresiones regulares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Eres capaz de crear una variable de formato (peso en kilos) a partir del nombre del producto, utilizando expresiones regulares?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
